数据的淘汰策略

当Redis中内存不够时，此时向Redis中添加新的key时，Redis会根据淘汰策略来决定删除哪些key。

Redis提供了8种淘汰策略：
1.noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，不淘汰key（默认的策略）。
2.volatile-ttl：对设置了TTL的key，比较key剩余的TTL值，TTL越小越优先淘汰。
3.allkeys-random：对全部的key，随机选择淘汰。
4.volatile-random：对于设置了TTL的key，随机选择淘汰。
5.allkeys-lru：对全部的key，基于LRU算法淘汰。 （业务上较多的场景）
6.volatile-lru：对于设置了TTL的key，基于LRU算法淘汰。
7.allkeys-lfu：对全部的key，基于LFU算法淘汰。
8.volatile-lfu：对于设置了TTL的key，基于LFU算法淘汰。

LRU（Last Recently Used） 最近最少使用，当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高
    Hash表 + 双向链表：利用Hash表确保数据查找的时间复杂度是O(1)，双向链表又可以使数据插入/删除等操作也是O(1)。
                     每次访问某个 key，就将其移动到链表头部；
                     淘汰时，从链表尾部删除最旧访问的 key。
LFU（Least Frequently Used） 最少频率使用，最不经常使用，访问次数越少，越优先淘汰

redis中的lru算法
    Redis 实现 LRU 算法时并没有精确计算每个数据的使用顺序，而是采用了 近似算法 来提高效率。
    Redis 利用 采样算法 来模拟 LRU 行为，而不是每次访问时都更新所有元素的访问顺序，Redis 的 LRU 实现称为 LRU-K（LRU-K Sampling）。

    Redis内部只使用Hash表缓存了数据，并没有创建一个专门针对LRU算法的双向链表，之所以这样处理也是因为以下几个原因：
    筛选规则：Redis是随机抽取一批数据去按照淘汰策略排序，不再需要对所有数据排序；
    性能问题：每次数据访问都可能涉及数据移位，性能会有少许损失；
    内存问题：Redis对内存的使用一向很“抠门”，数据结构都很精简，尽量不使用复杂的数据结构管理数据；
    策略配置：如果线上Redis实例动态修改淘汰策略会触发全部数据的结构性改变，这个Redis系统无法承受的。

    Redis的LRU 近似算法是指每次访问数据时并不会更新所有元素的顺序，而是通过随机抽取一定数量的键，估算这些键的使用频率来决定哪些键应该被淘汰。
    这种近似的方式避免了每次都精确计算访问顺序，减少了性能开销。
    在缓存满的时候，Redis 选择最近最少使用的元素进行淘汰。

如何判断“最近最少使用”的键？
    它的基本思路是：
    定期从缓存中随机挑选一部分数据。
    对这些随机选中的数据，检查它们的使用情况，找出最久未使用的键进行淘汰。
    采样的大小 是一个重要的参数。
    默认情况下，Redis 会随机抽取 10 个键，通过这些键来估算哪个是最近最少使用的。抽样的数量可以通过配置参数调整。

Redis 如何实现 LRU？
    Redis 没有使用传统 LRU，而是实现了近似 LRU，采用“随机采样 + 时间戳”方式。
    实现细节：
        Redis 为每个键的对象结构添加了 lru 字段，记录其最近访问时间（非绝对时间，是一个全局逻辑时钟）。
        Redis 每次进行内存淘汰时，并不会遍历所有键，而是从所有键中随机采样若干个（默认 10 个），然后挑出其中访问最久远的键淘汰。
        这个采样数量可通过参数 maxmemory-samples 配置。
        优点：
            无需维护全局链表，节省空间；
            不需要每次访问都做链表操作，大幅提高性能；
            适用于高性能场景的内存淘汰。
        缺点：
            由于是近似 LRU，并非全局最久未使用的键一定会被淘汰，存在一定误差；
            可能出现缓存污染问题：某些键被短时间大量访问后遗留在内存中，却很少被再次使用。


Redis 中 LFU 的实现方式：
    Redis 在每个键中增加了一个 访问频率计数器；
    每次访问某个 key，会更新其计数；
    内存淘汰时，采用类似于近似 LRU 的方式 —— 随机采样几个 key，选择访问频率最少的淘汰。
    优点：
        解决了 LRU 中“只访问一次却常驻内存”的问题；
        更适合处理热点数据与长尾数据共存的缓存场景。